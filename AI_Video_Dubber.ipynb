{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5d2cb2c",
   "metadata": {},
   "source": [
    "# ğŸ¬ AI Video Dubber â€” Hindi Dubbing Pipeline\n",
    "\n",
    "**One-click Kannada â†’ Hindi video dubbing** with voice cloning, lip-sync, and face restoration.\n",
    "\n",
    "### Setup\n",
    "1. **Runtime â†’ Change runtime type â†’ T4 GPU**\n",
    "2. Run all cells in order\n",
    "3. Find your output in `outputs/final_dubbed.mp4`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289c37d6",
   "metadata": {},
   "source": [
    "## Step 0: GPU Check & Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebbccfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify GPU is available\n",
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"âš ï¸ No GPU detected! Go to Runtime â†’ Change runtime type â†’ T4 GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe56d00",
   "metadata": {},
   "source": [
    "## Step 1: Clone Repository & Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df47560b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Clone the AI Video Dubber repository\n",
    "!git clone https://github.com/grafenx07/AI-video-dubber.git 2>/dev/null || echo \"Already cloned\"\n",
    "%cd AI-video-dubber\n",
    "\n",
    "# Check Python version\n",
    "import sys\n",
    "print(f\"Python: {sys.version}\")\n",
    "\n",
    "# Install core dependencies (without TTS first)\n",
    "!pip install -q openai-whisper deep-translator edge-tts nest-asyncio \\\n",
    "    gfpgan librosa soundfile pydub tqdm opencv-python-headless\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# FIX: Coqui TTS requires Python <3.12\n",
    "# Install coqui-tts fork that supports newer Python versions\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "if sys.version_info >= (3, 12):\n",
    "    print(\"\\nâš ï¸ Python 3.12+ detected â€” installing coqui-tts fork...\")\n",
    "    import subprocess\n",
    "    r = subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"coqui-tts\"],\n",
    "                       capture_output=True, text=True)\n",
    "    if r.returncode != 0:\n",
    "        r = subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
    "                           \"git+https://github.com/idiap/coqui-ai-TTS.git\"],\n",
    "                          capture_output=True, text=True)\n",
    "    if r.returncode != 0:\n",
    "        print(\"âš ï¸ TTS install failed â€” will use Edge TTS fallback (still good quality)\")\n",
    "else:\n",
    "    !pip install -q TTS\n",
    "\n",
    "# Install IndicTrans2 toolkit (optional â€” for better translation)\n",
    "!pip install -q IndicTransToolkit 2>/dev/null || echo \"IndicTrans2 not available, using Google Translate\"\n",
    "\n",
    "# Verify TTS availability\n",
    "try:\n",
    "    from TTS.api import TTS\n",
    "    print(\"\\nâœ… Coqui TTS installed â€” XTTS voice cloning available!\")\n",
    "except ImportError:\n",
    "    print(\"\\nâš ï¸ Coqui TTS not available â€” will use Edge TTS (still high quality Hindi)\")\n",
    "\n",
    "print(\"\\nâœ… All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f2ce3f",
   "metadata": {},
   "source": [
    "## Step 2: Setup Wav2Lip (Lip Synchronization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20d43dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Clone Wav2Lip\n",
    "if not os.path.exists(\"Wav2Lip\"):\n",
    "    !git clone https://github.com/Rudrabha/Wav2Lip.git\n",
    "    !cd Wav2Lip && pip install -q -r requirements.txt 2>/dev/null\n",
    "else:\n",
    "    print(\"Wav2Lip already cloned\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CRITICAL PATCHES for Wav2Lip compatibility\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "wav2lip_audio = \"Wav2Lip/audio.py\"\n",
    "if os.path.exists(wav2lip_audio):\n",
    "    with open(wav2lip_audio, \"r\") as f:\n",
    "        content = f.read()\n",
    "    original = content\n",
    "\n",
    "    # Fix 1: numpy >= 1.24 â€” np.float removed\n",
    "    content = content.replace(\"np.float)\", \"np.float64)\")\n",
    "    content = content.replace(\"np.float,\", \"np.float64,\")\n",
    "\n",
    "    # Fix 2: librosa >= 0.10 â€” mel() positional args removed\n",
    "    # Old: librosa.filters.mel(hp.sample_rate, hp.n_fft, n_mels=...)\n",
    "    # New: librosa.filters.mel(sr=hp.sample_rate, n_fft=hp.n_fft, n_mels=...)\n",
    "    content = content.replace(\n",
    "        \"librosa.filters.mel(hp.sample_rate, hp.n_fft,\",\n",
    "        \"librosa.filters.mel(sr=hp.sample_rate, n_fft=hp.n_fft,\"\n",
    "    )\n",
    "\n",
    "    if content != original:\n",
    "        with open(wav2lip_audio, \"w\") as f:\n",
    "            f.write(content)\n",
    "        print(\"âœ… Patched Wav2Lip/audio.py (numpy + librosa fixes)\")\n",
    "\n",
    "for fpath in [\"Wav2Lip/models/wav2lip.py\", \"Wav2Lip/models/wav2lip_gan.py\"]:\n",
    "    if os.path.exists(fpath):\n",
    "        with open(fpath, \"r\") as f:\n",
    "            content = f.read()\n",
    "        p = content.replace(\"np.float)\", \"np.float64)\")\n",
    "        if p != content:\n",
    "            with open(fpath, \"w\") as f:\n",
    "                f.write(p)\n",
    "            print(f\"âœ… Patched {fpath}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Monkey-patch torchvision for GFPGAN\n",
    "# torchvision.transforms.functional_tensor removed in v0.18+\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "try:\n",
    "    import torchvision.transforms.functional_tensor  # noqa\n",
    "except ModuleNotFoundError:\n",
    "    try:\n",
    "        import torchvision.transforms.functional as _F\n",
    "        sys.modules[\"torchvision.transforms.functional_tensor\"] = _F\n",
    "        print(\"âœ… Patched torchvision.transforms.functional_tensor\")\n",
    "    except ImportError:\n",
    "        pass\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Download Wav2Lip GAN model â€” HuggingFace mirrors\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "os.makedirs(\"Wav2Lip/checkpoints\", exist_ok=True)\n",
    "model_path = \"Wav2Lip/checkpoints/wav2lip_gan.pth\"\n",
    "\n",
    "def verify_model(path, min_size=100_000_000):\n",
    "    return os.path.exists(path) and os.path.getsize(path) > min_size\n",
    "\n",
    "def clean_partial(path):\n",
    "    if os.path.exists(path):\n",
    "        os.remove(path)\n",
    "\n",
    "if not verify_model(model_path):\n",
    "    clean_partial(model_path)\n",
    "    print(\"Downloading wav2lip_gan.pth...\")\n",
    "\n",
    "    !wget -q --show-progress -O {model_path} \\\n",
    "        \"https://huggingface.co/numz/wav2lip_studio/resolve/main/Wav2Lip/checkpoints/wav2lip_gan.pth\"\n",
    "\n",
    "    if not verify_model(model_path):\n",
    "        clean_partial(model_path)\n",
    "        !wget -q --show-progress -O {model_path} \\\n",
    "            \"https://huggingface.co/camenduru/Wav2Lip/resolve/main/checkpoints/wav2lip_gan.pth\"\n",
    "\n",
    "    if not verify_model(model_path):\n",
    "        clean_partial(model_path)\n",
    "        !gdown --id 1kMFGEASqoGA__fxJ0Z0mEKLpCyF52FK- -O {model_path} 2>/dev/null\n",
    "\n",
    "    if verify_model(model_path):\n",
    "        print(f\"âœ… wav2lip_gan.pth downloaded ({os.path.getsize(model_path)/1e6:.0f} MB)\")\n",
    "    else:\n",
    "        clean_partial(model_path)\n",
    "        print(\"âŒ wav2lip_gan.pth download FAILED! Pipeline will skip lip-sync.\")\n",
    "else:\n",
    "    print(f\"wav2lip_gan.pth already exists ({os.path.getsize(model_path)/1e6:.0f} MB)\")\n",
    "\n",
    "# Download face detection model\n",
    "face_det_dir = \"Wav2Lip/face_detection/detection/sfd\"\n",
    "os.makedirs(face_det_dir, exist_ok=True)\n",
    "if not os.path.exists(f\"{face_det_dir}/s3fd.pth\"):\n",
    "    !wget -q -O {face_det_dir}/s3fd.pth https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\n",
    "    print(\"âœ… s3fd.pth downloaded\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# VERIFY the patch actually applied\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "if os.path.exists(wav2lip_audio):\n",
    "    with open(wav2lip_audio, \"r\") as f:\n",
    "        check = f.read()\n",
    "    if \"librosa.filters.mel(hp.sample_rate, hp.n_fft,\" in check:\n",
    "        print(\"âš ï¸ WARNING: librosa patch did NOT apply! Attempting force patch...\")\n",
    "        check = check.replace(\n",
    "            \"librosa.filters.mel(hp.sample_rate, hp.n_fft,\",\n",
    "            \"librosa.filters.mel(sr=hp.sample_rate, n_fft=hp.n_fft,\"\n",
    "        )\n",
    "        with open(wav2lip_audio, \"w\") as f:\n",
    "            f.write(check)\n",
    "        print(\"âœ… Force-patched librosa.filters.mel()\")\n",
    "    else:\n",
    "        print(\"âœ… librosa patch verified OK\")\n",
    "\n",
    "print(\"\\nâœ… Wav2Lip setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e23ddeb",
   "metadata": {},
   "source": [
    "## Step 3: Download Source Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e276850",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import os\n",
    "\n",
    "# Download the Supernan training video from Google Drive\n",
    "VIDEO_FILE = \"supernan_training.mp4\"\n",
    "\n",
    "if not os.path.exists(VIDEO_FILE):\n",
    "    !pip install -q gdown\n",
    "    # Google Drive file ID from shared link\n",
    "    !gdown --id 1uDzLVEow_gAJsXnNjbSoskzVLZ4d7opW -O {VIDEO_FILE}\n",
    "    print(f\"\\nâœ… Video downloaded: {VIDEO_FILE}\")\n",
    "else:\n",
    "    print(f\"Video already exists: {VIDEO_FILE}\")\n",
    "\n",
    "# Show video info\n",
    "!ffprobe -v quiet -print_format json -show_format -show_streams {VIDEO_FILE} | python -m json.tool | head -30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7b67bf",
   "metadata": {},
   "source": [
    "## Step 4: Run the Dubbing Pipeline\n",
    "\n",
    "This runs the complete pipeline:\n",
    "1. Extract 15-second clip (0:15 - 0:30)\n",
    "2. Transcribe speech (Whisper translate mode â†’ English)\n",
    "3. Translate English â†’ Hindi (Google Translate â€” high quality)\n",
    "4. Generate Hindi speech with voice cloning (XTTS v2)\n",
    "5. Align audio duration to video\n",
    "6. Lip-sync video (Wav2Lip)\n",
    "7. Enhance face quality (GFPGAN)\n",
    "\n",
    "**Expected time: ~5-10 minutes on T4 GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad11d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "#  CONFIGURATION â€” Adjust these as needed!\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "INPUT_VIDEO = \"supernan_training.mp4\"\n",
    "START_TIME = 15      # Start at 0:15\n",
    "END_TIME = 30        # End at 0:30\n",
    "WHISPER_MODEL = \"medium\"   # Use 'medium' for better Kannada accuracy (small often fails)\n",
    "TRANSLATION = \"google\"     # google|indictrans2|seamless\n",
    "TTS_METHOD = \"xtts\"        # xtts|edge (auto-falls back to edge if needed)\n",
    "SPEECH_RATE = 1.05         # Slightly faster for Hindi\n",
    "\n",
    "# Run the pipeline\n",
    "!python dub_video.py \\\n",
    "    --input {INPUT_VIDEO} \\\n",
    "    --start {START_TIME} \\\n",
    "    --end {END_TIME} \\\n",
    "    --whisper-model {WHISPER_MODEL} \\\n",
    "    --translation {TRANSLATION} \\\n",
    "    --tts {TTS_METHOD} \\\n",
    "    --speech-rate {SPEECH_RATE} \\\n",
    "    --wav2lip-batch-size 8\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… Pipeline complete! Check outputs/final_dubbed.mp4\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd9cca8",
   "metadata": {},
   "source": [
    "## Step 5: Preview Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6f1cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the output video inline\n",
    "from IPython.display import HTML, display\n",
    "from base64 import b64encode\n",
    "import os\n",
    "\n",
    "output_video = \"outputs/final_dubbed.mp4\"\n",
    "\n",
    "if os.path.exists(output_video):\n",
    "    # Show video inline\n",
    "    video_data = open(output_video, \"rb\").read()\n",
    "    b64 = b64encode(video_data).decode()\n",
    "    display(HTML(f\"\"\"\n",
    "    <h3>ğŸ¬ Final Dubbed Video</h3>\n",
    "    <video width=\"640\" controls>\n",
    "        <source src=\"data:video/mp4;base64,{b64}\" type=\"video/mp4\">\n",
    "    </video>\n",
    "    \"\"\"))\n",
    "\n",
    "    # Show file info\n",
    "    size_mb = os.path.getsize(output_video) / (1024 * 1024)\n",
    "    print(f\"\\nFile: {output_video}\")\n",
    "    print(f\"Size: {size_mb:.1f} MB\")\n",
    "else:\n",
    "    print(\"âŒ Output video not found. Check pipeline logs for errors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6930bf24",
   "metadata": {},
   "source": [
    "## Step 6: Review Intermediate Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdfe121",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Show transcription\n",
    "transcription_file = \"outputs/03_transcription.json\"\n",
    "if os.path.exists(transcription_file):\n",
    "    with open(transcription_file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    print(\"ğŸ“ Kannada Transcription:\")\n",
    "    print(f\"   {data['text']}\")\n",
    "    print(f\"   Segments: {len(data.get('segments', []))}\")\n",
    "    print()\n",
    "\n",
    "# Show translation\n",
    "translation_file = \"outputs/04_translation.json\"\n",
    "if os.path.exists(translation_file):\n",
    "    with open(translation_file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    print(\"ğŸŒ Hindi Translation:\")\n",
    "    print(f\"   {data['full_text']}\")\n",
    "    print()\n",
    "    if data.get('segments'):\n",
    "        print(\"   Segment-by-segment:\")\n",
    "        for seg in data['segments']:\n",
    "            print(f\"   [{seg['start']:.1f}s-{seg['end']:.1f}s] {seg['original']}\")\n",
    "            print(f\"   â†’ {seg['translated']}\")\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f284867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play the Hindi audio\n",
    "from IPython.display import Audio, display\n",
    "import os\n",
    "\n",
    "for audio_file, label in [\n",
    "    (\"outputs/02_audio.wav\", \"Original Kannada Audio\"),\n",
    "    (\"outputs/05_hindi_raw.wav\", \"Generated Hindi Audio (raw)\"),\n",
    "    (\"outputs/06_hindi_aligned.wav\", \"Hindi Audio (aligned to video)\"),\n",
    "]:\n",
    "    if os.path.exists(audio_file):\n",
    "        print(f\"\\nğŸ”Š {label}:\")\n",
    "        display(Audio(audio_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ef1ae4",
   "metadata": {},
   "source": [
    "## Step 7: Download Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007c316e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the final video\n",
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "output_video = \"outputs/final_dubbed.mp4\"\n",
    "if os.path.exists(output_video):\n",
    "    files.download(output_video)\n",
    "    print(\"âœ… Download started!\")\n",
    "else:\n",
    "    print(\"âŒ Output not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3f4bf5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ”§ Troubleshooting\n",
    "\n",
    "| Issue | Solution |\n",
    "|-------|----------|\n",
    "| `CUDA out of memory` | Reduce `--wav2lip-batch-size` to 4, use `--whisper-model base` |\n",
    "| `Wav2Lip model not found` | Re-run Step 2 or download manually |\n",
    "| `No GPU available` | Runtime â†’ Change runtime type â†’ T4 GPU |\n",
    "| `Edge TTS timeout` | Retry or switch to `--tts xtts` |\n",
    "| `Translation is too literal` | Use `--translation indictrans2` for better Hindi |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386b1949",
   "metadata": {},
   "source": [
    "## ğŸ“Š Quick Alternative: Skip Heavy Steps\n",
    "\n",
    "If Wav2Lip or GFPGAN are causing issues, run without them for a quick result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724e95ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick mode: Audio-only dubbing (no lip-sync, no enhancement)\n",
    "# Good for testing translation + voice cloning quality\n",
    "\n",
    "!python dub_video.py \\\n",
    "    --input supernan_training.mp4 \\\n",
    "    --start 15 --end 30 \\\n",
    "    --skip-lipsync \\\n",
    "    --skip-enhancement \\\n",
    "    --output-dir outputs_quick"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
